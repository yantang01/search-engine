A web crawler using Python that repeatedly extracts URLs and words from web pages that saves desired data
into text files

## Steps to run in dev environment:

- clone repo
- call the crawl function in the crawler.py module and pass a seed website as a parameter
- call the search function in the search.py module. The first parameter is your search query, and the second parameter is a boolean value whether you want to boost your result or not
- python3 crawler.py
- python3 search.py

You only have to run crawler.py once for one website.
